##### Hive用类SQL的语法封装MapReduce过程
    Hive是基于Hadoop构建的，简单地说就是一套Hadoop的访问接口
    hive table
    数据 + 表格数据形式元数据
    hdfs    关系型数据库
    文件目录

    两种表类型
    托管表                         外部表
    hive数据仓库 hdfs目录

    表 分区   -> 目录级别的拆分数据
    bucket   -> 数据源数据文件拆分数据
    hadoop里面有自己定义的序列化格式：writable

    mapreduce运行机制
    按照时间顺序包括：
    (1)输入分片（input split）
    分片长度+记录数据位置的数组
    (2)map阶段
    在数据存储节点上进行
    (3)combiner阶段
    可选 一种reduce 在map计算出中间文件前做一个简单的合并重复key值的操作
    (4)shuffle阶段
    将map的输出作为reduce的输入的过程
    (5)reduce阶段
    合并map输出文件


    比较Spark和MapReduce
    优势包括：
    1 事件触发任务执行的机制优于MR的心跳触发任务执行机制
    2 DAG的任务调度执行机制优于MR的迭代执行机制

    Storm优势就在于Storm是实时的连续性的分布式的计算框架,一旦运行起来,除非你将它杀掉,否则它一直处理计算或等待计算的状态.Spark和hadoop都做不到.
    当然它们各自都有其应用场景,各有各的优势.可以配合使用.
    下面我转一份别人的资料,讲的很清楚.
    Storm与Spark、Hadoop这三种框架，各有各的优点，每个框架都有自己的最佳应用场景。
    所以，在不同的应用场景下，应该选择不同的框架。
    Storm是最佳的流式计算框架，Storm由Java和Clojure写成，Storm的优点是全内存计算，所以它的定位是分布式实时计算系统，按照Storm作者的说法，Storm对于实时计算的意义类似于Hadoop对于批处理的意义。
    Storm的适用场景：
    1）流数据处理
    Storm可以用来处理源源不断流进来的消息，处理之后将结果写入到某个存储中去。
    2）分布式RPC。由于Storm的处理组件是分布式的，而且处理延迟极低，所以可以作为一个通用的分布式RPC框架来使用。
    SparkSpark是一个基于内存计算的开源集群计算系统，目的是更快速的进行数据分析。Spark由加州伯克利大学AMP实验室Matei为主的小团队使用Scala开发开发，类似于Hadoop MapReduce的通用并行计算框架，Spark基于Map Reduce算法实现的分布式计算，拥有Hadoop MapReduce所具有的优点，但不同于MapReduce的是Job中间输出和结果可以保存在内存中，从而不再需要读写HDFS，因此Spark能更好地适用于数据挖掘与机器学习等需要迭代的Map Reduce的算法。
    Spark的适用场景：
    1）多次操作特定数据集的应用场合
    Spark是基于内存的迭代计算框架，适用于需要多次操作特定数据集的应用场合。需要反复操作的次数越多，所需读取的数据量越大，受益越大，数据量小但是计算密集度较大的场合，受益就相对较小。
    2）粗粒度更新状态的应用
    由于RDD的特性，Spark不适用那种异步细粒度更新状态的应用，例如Web服务的存储或者是增量的Web爬虫和索引。就是对于那种增量修改的应用模型不适合。
    总的来说Spark的适用面比较广泛且比较通用。
    Hadoop是实现了MapReduce的思想，将数据切片计算来处理大量的离线数据数据。Hadoop处理的数据必须是已经存放在HDFS上或者类似HBase的数据库中，所以Hadoop实现的时候是通过移动计算到这些存放数据的机器上来提高效率。
    Hadoop的适用场景：
    1）海量数据的离线分析处理
    2）大规模Web信息搜索
    3）数据密集型并行计算
    简单来说：
    Hadoop适合于离线的批量数据处理适用于对实时性要求极低的场景
    Storm适合于实时流数据处理，实时性方面做得极好
    Spark是内存分布式计算框架，试图吞并Hadoop的Map-Reduce批处理框架和Storm的流处理框架，但是Spark已经做得很不错了，批处理方面性能优于Map-Reduce，但是流处理目前还是弱于Storm，产品仍在改进之中

    Hive和Pig都是Hadoop中的项目，并且Hive和pig有很多共同点，但Hive还似乎有点数据库的影子，而Pig基本就是一个对MapReduce实现的工具(脚本)。两者都拥有自己的表达语言，其目的是将MapReduce的实现进行简化，并且读写操作数据最终都是存储在HDFS分布式文件系统上
